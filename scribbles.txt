Lunar Lander Data:
Random Learner: [-452.174421901032, -662.972353362637, -396.7225915034367, -391.2459664314594, -752.7123294505722, -840.8575139628855, -503.8150841488567, -557.8205799335751, -484.8628417114906, -826.2194609862426] - -586.94

50:
[-116.07331718220934, -168.26066129030883, -102.28421135507219, -128.07081279600067, -159.25804751333152, -159.33521623056896, -124.45676349153544, -141.8686150187554, -130.18098470010267, -161.6648556818255] - -139.15

100:
[-45.133180523931, 18.557822861491488, -49.64128003491058, -273.82552530486225, -67.6139264252351, 247.4187635619935, -57.90128957767379, -24.83376620606046, -47.48081922204537, 37.83739189936702] - -26.26

200:
[23.009141065573175, -47.96259643787111, -101.8860423584971, -352.94496865138535, -243.2148964423845, 260.482302178953, 39.836824371347205, -63.68445716189174, 207.64631325916193, -14.695851816910121] - -29.34

The reasons for this levelling off is I believe bc of Classification error and reaching the bound of what the human is capable of.

Human:
[20.494986652965707, 12.056358857716006, 7.597910769809147, 26.978723136250068, 14.54585273818806, -7.029402558066721,
38.87699441395901, -13.453444146078269, 24.20827579237242, 14.164150958371721] - 13.844040661548714

Mountain Car Data:
DQN was awful
Reason - DQN is no good in 'poorly-informative rewards' as all rewards are -1 till the end the Q-learning algorithm which
because of its random sampling disregards context and trajectory-dependent information will gradually just decrease
all Q-values leading to a overly-pessimistic model which belives all possible states and actions are terrible